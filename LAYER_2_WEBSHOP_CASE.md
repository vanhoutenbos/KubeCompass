# Layer 2: Platform Enhancements & Resilience â€” Decision Framework

**Doelgroep**: Platform Engineers, DevOps Engineers, SREs, Architects  
**Type**: Decision Framework & Capability Mapping  
**Organisatie**: Nederlandse webshop / online warenhuis met Essential SAFe werkwijze  
**Voorwaarde**: Layer 0 en Layer 1 zijn **geanalyseerd en gestructureerd** (niet per se geÃ¯mplementeerd)  

---

## âš ï¸ Belangrijk: Dit is GEEN Implementatiegids

**Dit document is:**
- ğŸ¯ Een **decision framework** voor wanneer Layer 2 capabilities relevant worden
- ğŸ§­ Een **capability map** met keuzeruimte en trade-offs
- ğŸ’¡ Een **denkraam** voor volwassen platformteams
- ğŸ“š Een **referentie** voor architectuurbeslissingen
- ğŸ¤– **Input voor AI agents** om architectuurkeuzes te redeneren

**Dit document is NIET:**
- âŒ Een deployment guide
- âŒ Een Helm/Terraform tutorial
- âŒ Een "copy-paste en deployen" handleiding
- âŒ Een vervanging voor vendor documentatie
- âŒ Een implementatie die je 1-op-1 kunt draaien

---

## Leeswijzer

ğŸ¯ **[TRIGGER]** - Wanneer wordt deze capability relevant?  
ğŸ”€ **[TRADE-OFFS]** - Welke keuzes heb je en wat zijn de afwegingen?  
âš ï¸ **[TIMING]** - Waarom nu wel/niet implementeren?  
ğŸ’­ **[BESLUITPUNT]** - Welke vragen moet je kunnen beantwoorden?  
ğŸ”— **[LAYER 1 LINK]** - Hoe bouwt dit op Layer 1?  

---

## Executive Summary

Dit document beschrijft **Layer 2: Platform Enhancements & Resilience** â€” het **besluitvormingsproces** voor geavanceerde platform capabilities nadat de Layer 1 basis stabiel is.

### Context: Van Layer 1 naar Layer 2

**Layer 1 (Fundament)** gaat over:
- Cluster draait
- GitOps werkt
- Basic observability (metrics, logs)
- Network policies bestaan
- Deployments lukken

**Layer 2 (Enhancement)** gaat over **maturity en optimization**:
- Wat gebeurt er **tussen** services? â†’ service mesh
- Hoe **traceer** je een request end-to-end? â†’ distributed tracing
- Hoe **test** je failure scenarios? â†’ chaos engineering
- Hoe **forceer** je security policies? â†’ policy enforcement
- Waar gaat het **geld** naartoe? â†’ cost visibility
- Zijn we **klaar** voor multi-region? â†’ architectural readiness

### Kernvraag Layer 2

> **"Wanneer wordt deze complexity investment de moeite waard?"**

Niet: "Welke tool is het beste?"  
Maar: "**Onder welke omstandigheden zou ik dit Ã¼berhaupt willen?**"

---

## Decision Matrix: Layer 1 â†’ Layer 2 Triggers

| Capability | Trigger Condition | Complexity Cost | Skip If... |
|-----------|-------------------|----------------|------------|
| **Service Mesh** | > 5 microservices, security/observability per-service | Medium-High | Monolith of < 3 services |
| **Distributed Tracing** | Debugging cross-service issues takes > 1h | Medium | < 5 services, simple call chains |
| **Chaos Engineering** | Production incidents, HA validation needed | Low-Medium | Dev environment, single instance |
| **Policy Enforcement** | Compliance requirement, > 10 developers | Medium | Small team, manual review werkt |
| **Cost Visibility** | Budget concerns, multi-tenant | Low | Single team, vaste kosten |
| **Multi-Region Readiness** | Latency requirements, DR strategy | High | Single region voldoet, geen DR eis |
| **Enhanced Auditing** | GDPR/DORA compliance, security team | Medium | Geen compliance eis |

---

## 1. Service Mesh

### ğŸ¯ [TRIGGER] Wanneer Relevant?

**Implementeer een service mesh wanneer:**
- âœ… Je **> 5 microservices** hebt met complexe inter-service communicatie
- âœ… Je **per-service security** wilt (mTLS zonder code changes)
- âœ… Je **gedetailleerde service-level metrics** nodig hebt (latency, error rate, traffic)
- âœ… Je **canary deployments** of **traffic splitting** wilt doen
- âœ… Je **service topology** en **dependency mapping** wilt visualiseren

**NIET implementeren wanneer:**
- âŒ Je een **monolith** hebt of **< 3 services**
- âŒ Je team **geen capaciteit** heeft voor extra operationele overhead
- âŒ **Network policies (L3/L4)** voldoende zijn voor je security model
- âŒ Basic Prometheus metrics genoeg informatie geven

### ğŸ”€ [TRADE-OFFS] Keuzeruimte

| Tool | Pro | Contra | Use When |
|------|-----|--------|----------|
| **Linkerd** | Kleinste footprint, eenvoudig, auto-mTLS | Minder features dan Istio | Klein team, eenvoudige use case |
| **Istio** | Feature-rich, enterprise support, mature | Complex, resource-intensive | Grote org, complexe routing |
| **Cilium Service Mesh** | eBPF-based (zeer performant), CNI-integratie | Beta, minder mature | Al Cilium CNI, early adopter |
| **Consul Connect** | Multi-datacenter native, HashiCorp stack | Vereist Consul infra | Al HashiCorp stack (Vault, Nomad) |

### ğŸ’­ [BESLUITPUNT] Vragen om te Beantwoorden

1. **Hebben we nu een probleem dat een service mesh oplost?**
   - Hebben we incidents gehad door miscommunicatie tussen services?
   - Missen we visibility in service-to-service latencies?
   - Is onze huidige security model (network policies) onvoldoende?

2. **Kunnen we de operationele overhead aan?**
   - Hebben we capacity voor learning curve?
   - Kunnen we sidecar injection debuggen?
   - Hebben we monitoring voor mesh health?

3. **Wat is onze exit strategy?**
   - Kunnen we terug naar geen mesh zonder grote refactor?
   - Zijn we vendor-locked?

### âš ï¸ [TIMING] Waarom Nu Wel/Niet?

**Implementeer NU als:**
- Je microservices in productie draait
- Je security compliance vereist (mTLS everywhere)
- Je debugging cross-service issues > 4 uur per week kost

**Wacht LATER als:**
- Layer 1 nog niet stabiel is
- Je < 5 services hebt
- Team nog geen Kubernetes-ervaring heeft

### ğŸ”— [LAYER 1 LINK]

**Bouwt op:**
- Cilium CNI (Layer 1) â†’ Service mesh voegt L7 visibility toe
- Prometheus (Layer 1) â†’ Service mesh voegt per-service golden signals toe
- Network Policies (Layer 1) â†’ Service mesh voegt mTLS toe (zero-trust)

**Vervangat niet:**
- Network policies blijven relevant (defense in depth)
- Cilium CNI blijft, service mesh is additive

---

## 2. Distributed Tracing

### ğŸ¯ [TRIGGER] Wanneer Relevant?

**Implementeer distributed tracing wanneer:**
- âœ… Je **> 5 microservices** hebt met **complexe call chains**
- âœ… **Debugging cross-service issues** > 1 uur per incident duurt
- âœ… Je **root cause analysis** van performance problemen nodig hebt
- âœ… Je **service dependencies** wilt begrijpen (dependency graph)
- âœ… Je **correlatie** tussen logs/metrics/traces wilt (observability maturity)

**NIET implementeren wanneer:**
- âŒ Je **< 5 services** hebt met simpele call chains
- âŒ **Logs + metrics** voldoende zijn voor debugging
- âŒ Je geen **storage budget** hebt voor traces (hoge data volume)
- âŒ Team geen tijd heeft voor **service instrumentation**

### ğŸ”€ [TRADE-OFFS] Keuzeruimte

| Approach | Pro | Contra | Use When |
|----------|-----|--------|----------|
| **OpenTelemetry + Jaeger** | Open standard, vendor-neutral, mature | Storage overhead, setup complexity | Self-hosted, vendor independence |
| **OpenTelemetry + Tempo** | Grafana native, S3 storage, cost-efficient | Nieuwer dan Jaeger, minder features | Al Grafana stack, S3 beschikbaar |
| **Cloud Provider (X-Ray, AppInsights)** | Managed, auto-instrumentation | Vendor lock-in, kosten | Al in die cloud, geen self-host |
| **Zipkin** | Lightweight, eenvoudig | Minder actief dan Jaeger | Legacy use case |

### ğŸ’­ [BESLUITPUNT] Vragen om te Beantwoorden

1. **Wat is de business impact van slow debugging?**
   - Hoeveel tijd kost cross-service debugging per week?
   - Hoeveel klantimpact hebben performance issues?

2. **Kunnen we services instrumenteren?**
   - Hebben we ownership per service (voor SDK integratie)?
   - Kunnen we auto-instrumentation gebruiken (.NET, Java)?
   - Hebben we capacity voor manual instrumentation (Go, Python)?

3. **Wat is onze trace retention strategie?**
   - Hoeveel dagen traces bewaren? (storage kosten!)
   - Sampling ratio (100% dev, 10% prod, 1% for high-traffic)?

### âš ï¸ [TIMING] Waarom Nu Wel/Niet?

**Implementeer NU als:**
- Debugging cross-service issues > 1 uur per incident
- Je production incidents hebt zonder duidelijke root cause
- Je service dependencies onbekend zijn (shadow dependencies)

**Wacht LATER als:**
- Je < 5 services hebt
- Logs + metrics voldoende zijn
- Geen budget voor trace storage (TB's per maand!)

### ğŸ”— [LAYER 1 LINK]

**Bouwt op:**
- Prometheus (Layer 1) â†’ Traces voegen request-level detail toe
- Loki (Layer 1) â†’ Trace ID in logs voor correlatie
- Grafana (Layer 1) â†’ Unified view (metrics + logs + traces)

---

## 3. Chaos Engineering

### ğŸ¯ [TRIGGER] Wanneer Relevant?

**Implementeer chaos engineering wanneer:**
- âœ… Je **HA (High Availability) claimt** maar niet test
- âœ… Je **production incidents** wilt voorkomen door proactief testen
- âœ… Je **RTO/RPO** wilt valideren (Disaster Recovery testing)
- âœ… Je **team confidence** wilt bouwen in platform resilience
- âœ… Je **SLO's** hebt die je wilt valideren

**NIET implementeren wanneer:**
- âŒ Je **geen HA setup** hebt (single replica, single node)
- âŒ Je **Layer 1 basis niet stabiel** is
- âŒ Team **geen tijd** heeft voor experiment analysis
- âŒ Je **geen monitoring** hebt om impact te meten

### ğŸ”€ [TRADE-OFFS] Keuzeruimte

| Tool | Pro | Contra | Use When |
|------|-----|--------|----------|
| **Chaos Mesh** | K8s-native, rich scenarios, GitOps | Chinees project (governance concern?) | Self-hosted, veel scenarios |
| **LitmusChaos** | CNCF project, community-driven | Complex setup | CNCF preference |
| **Gremlin** | Enterprise support, managed | Commercial, niet self-hosted | Budget beschikbaar, managed voorkeur |
| **AWS/Azure Chaos** | Cloud-native, provider integratie | Vendor lock-in | Al in die cloud |

### ğŸ’­ [BESLUITPUNT] Vragen om te Beantwoorden

1. **Wat is onze chaos maturity?**
   - Hebben we HA setup (meerdere replicas, nodes)?
   - Hebben we PodDisruptionBudgets?
   - Hebben we readiness/liveness probes?

2. **Welke failure scenarios zijn relevant?**
   - Pod crash? (test: K8s restart werkt)
   - Node failure? (test: pod scheduling op andere node)
   - Network partition? (test: services blijven beschikbaar)
   - Resource stress? (test: HPA scaling werkt)

3. **Hoe meten we success?**
   - SLO's blijven binnen target? (99.9% uptime maintained)
   - Alerts triggeren correct?
   - Automated recovery werkt?

### âš ï¸ [TIMING] Waarom Nu Wel/Niet?

**Implementeer NU als:**
- Je HA claimt maar nooit test
- Je production incidents hebt door failure scenarios
- Je confidence wilt bouwen in platform resilience

**Wacht LATER als:**
- Layer 1 nog niet stabiel is
- Je geen HA setup hebt
- Geen monitoring om impact te meten

### ğŸ”— [LAYER 1 LINK]

**Bouwt op:**
- Velero (Layer 1) â†’ Chaos test: cluster restore werkt?
- Prometheus (Layer 1) â†’ Chaos experiments zichtbaar in metrics
- HA setup (Layer 1) â†’ Chaos valideert dat HA daadwerkelijk werkt

---

## 4. Policy Enforcement (Low Trust)

### ğŸ¯ [TRIGGER] Wanneer Relevant?

**Implementeer policy enforcement wanneer:**
- âœ… Je **> 10 developers** hebt die niet allemaal K8s-experts zijn
- âœ… Je **compliance vereisten** hebt (GDPR, DORA, PCI-DSS)
- âœ… Je **security incidents** hebt gehad door misconfiguraties
- âœ… Je **automated validation** wilt voor deployments
- âœ… Je **audit trail** nodig hebt voor wie-wat-wanneer

**NIET implementeren wanneer:**
- âŒ Je **< 5 developers** hebt die allemaal K8s-experts zijn
- âŒ **Manual review** proces werkt goed
- âŒ Geen compliance requirements
- âŒ Team kan policy complexity niet aan

### ğŸ”€ [TRADE-OFFS] Keuzeruimte

| Tool | Pro | Contra | Use When |
|------|-----|--------|----------|
| **Kyverno** | YAML-based (geen Rego), mutations, generate policies | Minder krachtig dan OPA | Developer-friendly, eenvoud |
| **OPA Gatekeeper** | Zeer krachtig (Rego), mature, CNCF | Rego learning curve, complex | Security team, complexe policies |
| **Kubewarden** | Policies in Rust/Go/etc, WebAssembly | Nieuw, kleine community | Bleeding edge, WASM fans |
| **Pod Security Admission** | K8s native, gratis | Alleen pod security, niet extensible | Basis security, geen custom policies |

### ğŸ’­ [BESLUITPUNT] Vragen om te Beantwoorden

1. **Welke policies zijn kritisch?**
   - No privileged containers? (security critical)
   - Resource limits verplicht? (capacity management)
   - Trusted registry only? (supply chain security)
   - Network policies verplicht? (network security)

2. **Wat is onze enforcement strategie?**
   - Start in **audit mode** (1 maand: collect violations)
   - Gradual **warnings** (1 maand: teams fixen violations)
   - Per-policy **enforce mode** (dev â†’ staging â†’ production)

3. **Wat is onze exception strategie?**
   - Wie kan policy exceptions goedkeuren?
   - Hoe lang zijn exceptions geldig?
   - Audit trail voor exceptions?

### âš ï¸ [TIMING] Waarom Nu Wel/Niet?

**Implementeer NU als:**
- Je compliance requirements hebt
- Je security incidents hebt door misconfigs
- Je > 10 developers hebt

**Wacht LATER als:**
- Je < 5 developers hebt
- Manual review werkt prima
- Team heeft geen capacity voor policy management

### ğŸ”— [LAYER 1 LINK]

**Bouwt op:**
- Pod Security Standards (Layer 1) â†’ Policies enforce PSS automatisch
- Network Policies (Layer 1) â†’ Policy generates default-deny
- RBAC (Layer 1) â†’ Policy audit RBAC changes

---

## 5. Cost Visibility

### ğŸ¯ [TRIGGER] Wanneer Relevant?

**Implementeer cost visibility wanneer:**
- âœ… Je **budget concerns** hebt (kosten stijgen onverwacht)
- âœ… Je **multi-tenant cluster** hebt (kosten allocatie per team)
- âœ… Je **showback/chargeback** wilt doen per team/project
- âœ… Je **idle resources** wilt identificeren (cost optimization)
- âœ… Je **capacity planning** wilt baseren op daadwerkelijk gebruik

**NIET implementeren wanneer:**
- âŒ Je **single tenant** bent met **vaste kosten**
- âŒ **Cloud kosten zijn geen concern** (budget ruim voldoende)
- âŒ Basic CPU/memory metrics uit Prometheus voldoende zijn
- âŒ Team heeft geen tijd voor cost optimization

### ğŸ”€ [TRADE-OFFS] Keuzeruimte

| Tool | Pro | Contra | Use When |
|------|-----|--------|----------|
| **Kubecost** | Feature-rich, recommendations, multi-cloud | Commercial (gratis versie OK) | Full-featured, single cluster |
| **OpenCost** | 100% open-source, CNCF sandbox | Minder features dan Kubecost | Budget constraint, basics |
| **Cloud Provider Tools** | Native integratie, managed | Vendor lock-in, niet K8s-native | Al in die cloud, native voorkeur |

### ğŸ’­ [BESLUITPUNT] Vragen om te Beantwoorden

1. **Wat willen we weten?**
   - Kosten per namespace? (multi-tenancy)
   - Kosten per service? (microservices cost attribution)
   - Idle resource cost? (optimization opportunities)
   - Trend analysis? (groei voorspellen)

2. **Wat doen we met de data?**
   - Showback (informative)? â†’ OpenCost voldoende
   - Chargeback (financieel)? â†’ Kubecost aanbevolen
   - Optimization (rightsizing)? â†’ Kubecost recommendations

3. **Wat is onze cost optimization strategie?**
   - Automated rightsizing? (risky!)
   - Manual review (monthly)? (safe)
   - Alert on anomalies? (proactive)

### âš ï¸ [TIMING] Waarom Nu Wel/Niet?

**Implementeer NU als:**
- Kosten stijgen onverwacht (> 20% per maand)
- Je multi-tenant bent (kosten allocatie onduidelijk)
- Management vraagt cost visibility

**Wacht LATER als:**
- Single tenant, vaste kosten
- Budget ruim voldoende
- Geen capacity voor cost optimization

### ğŸ”— [LAYER 1 LINK]

**Bouwt op:**
- Prometheus (Layer 1) â†’ Kubecost gebruikt CPU/memory metrics
- Resource limits (Layer 1) â†’ Cost tool toont waste (limits vs usage)

---

## 6. Multi-Region Readiness

### ğŸ¯ [TRIGGER] Wanneer Relevant?

**Overweeg multi-region wanneer:**
- âœ… Je **gebruikers in meerdere regio's** hebt met **latency requirements**
- âœ… Je **Disaster Recovery** strategie multi-region vereist (RTO < 1h)
- âœ… Je **data residency** requirements hebt (GDPR: EU data in EU)
- âœ… Je **traffic growth** verwacht die single region niet aankan

**NIET implementeren wanneer:**
- âŒ **Single region voldoet** voor je use case
- âŒ Je **geen DR requirement** hebt
- âŒ **Complexity** outweighs benefits (multi-region is HARD)
- âŒ Je **database** is niet multi-region ready (biggest blocker!)

### ğŸ”€ [TRADE-OFFS] Architectural Choices

| Approach | Pro | Contra | Use When |
|----------|-----|--------|----------|
| **Active-Active (beide regio's live)** | Beste latency, beste HA | Zeer complex, data sync issues | Mission-critical, budget |
| **Active-Passive (1 live, 1 standby)** | Simpeler, DR capability | Standby idle (kosten), RTO > 5 min | DR requirement, niet latency |
| **Read Replicas (DB per regio)** | Beste latency, simpeler | Eventual consistency, complex writes | Read-heavy workload |

### ğŸ’­ [BESLUITPUNT] Vragen om te Beantwoorden

1. **Wat is onze multi-region strategie?**
   - **NOT NOW**: Single region in Layer 2
   - **LATER**: Multi-region in Layer 3 (indien nodig)
   - **PREPAREDNESS**: Architectuur moet het niet blokkeren

2. **Is onze architectuur multi-region ready?**
   - âœ… **Stateless services** (horizontally scalable)
   - âœ… **Shared database** (read replicas mogelijk)
   - âœ… **Session state in cache** (Redis/Valkey kan regionaal)
   - â“ **Database replicatie** (biggest challenge!)

3. **Wat zijn onze blockers?**
   - Database (PostgreSQL multi-region replicatie?)
   - Stateful workloads (persistent volumes regional)
   - Cost (double infrastructure)

### âš ï¸ [TIMING] Waarom Nu Wel/Niet?

**Voorbereiden NU (niet activeren!):**
- Architectuur moet multi-region niet blokkeren
- Cilium Cluster Mesh optie enabled (niet gebruikt)
- DR scenario's documenteren

**Activeren LATER (Layer 3):**
- Alleen als business case duidelijk is
- Database strategie duidelijk is
- Team capacity heeft

### ğŸ”— [LAYER 1 LINK]

**Bouwt op:**
- Cilium CNI (Layer 1) â†’ Cluster Mesh capability voor multi-region
- Velero (Layer 1) â†’ Backup restore in andere regio (DR)
- Stateless design (Layer 1) â†’ Maakt multi-region mogelijk

---

## 7. Observability Uitbreiding

### ğŸ¯ [TRIGGER] Wanneer Relevant?

**Verhoog observability maturity wanneer:**
- âœ… Je **Layer 1 observability** (metrics, logs) niet voldoende is
- âœ… Je **alerting strategie** onduidelijk is (alles is pager-worthy?)
- âœ… Je **correlation** tussen metrics/logs/traces wilt
- âœ… Je **SLO's** wilt monitoren (error budget)

### ğŸ”€ [TRADE-OFFS] Alerting Strategie

| Alert Level | Trigger | Action | Destination | Example |
|------------|---------|--------|-------------|---------|
| **CRITICAL** | Service down, data loss risk | Page on-call | PagerDuty | App down, DB unreachable |
| **WARNING** | Degraded performance | Notify team | Slack | High latency, high CPU |
| **INFO** | Routine events | Log only | Dashboard | Deployment success, backup OK |

### ğŸ’­ [BESLUITPUNT] Vragen om te Beantwoorden

1. **Wat is pager-worthy?**
   - **CRITICAL**: Production down, payment failures, data loss
   - **WARNING**: Slow performance, high resource usage
   - **INFO**: Successful deployments, routine events

2. **Hoe correleren we observability data?**
   - Trace ID in logs (structured logging)
   - Exemplars in Prometheus (metrics â†’ traces)
   - Grafana Explore (unified view)

3. **Wat is onze SLO strategie?**
   - Define SLO's (99.9% uptime, P95 < 200ms)
   - Monitor error budget
   - Alert on budget burn rate

### âš ï¸ [TIMING] Waarom Nu Wel/Niet?

**Verhoog maturity NU als:**
- Alert fatigue (te veel alerts, team negeert)
- Debugging is slow (geen correlatie tussen metrics/logs/traces)
- SLO's zijn undefined (geen error budget)

**Wacht LATER als:**
- Layer 1 observability werkt prima
- Alert strategie is duidelijk
- Team heeft geen capacity

### ğŸ”— [LAYER 1 LINK]

**Bouwt op:**
- Prometheus (Layer 1) â†’ Enhanced met SLO monitoring
- Loki (Layer 1) â†’ Enhanced met structured logging + trace ID
- Grafana (Layer 1) â†’ Enhanced met unified observability

---

## 8. Security & Auditing

### ğŸ¯ [TRIGGER] Wanneer Relevant?

**Verhoog audit maturity wanneer:**
- âœ… Je **compliance requirements** hebt (GDPR, DORA, ISO 27001)
- âœ… Je **security incidents** wilt kunnen investigeren
- âœ… Je **break-glass procedures** nodig hebt (emergency access)
- âœ… Je **SIEM integratie** wilt (centralized security monitoring)

**NIET implementeren wanneer:**
- âŒ Geen compliance requirements
- âŒ Basic K8s audit logs voldoende zijn
- âŒ Geen security team

### ğŸ”€ [TRADE-OFFS] Audit Strategie

| Component | Audit What | Retention | Use When |
|-----------|------------|-----------|----------|
| **K8s Audit Logs** | API calls (kubectl, RBAC) | 1 jaar | Compliance |
| **ArgoCD Audit** | GitOps syncs, manual approvals | 1 jaar | Deployment audit |
| **Vault Audit** | Secret access (read/write) | 1 jaar | Secret compliance |

### ğŸ’­ [BESLUITPUNT] Vragen om te Beantwoorden

1. **Wat moeten we auditen?**
   - K8s API calls (wie deed wat wanneer)
   - GitOps syncs (welke change, door wie)
   - Secret access (wie las welke secret)
   - Break-glass usage (emergency access audit)

2. **Wat is onze break-glass strategie?**
   - Hoe krijg je emergency access? (privilege escalation tool)
   - Hoelang geldig? (max 1 uur)
   - Hoe loggen we dit? (full audit trail)
   - Post-incident review? (verplicht)

3. **Hoe integreren we met SIEM?**
   - Welke SIEM? (Splunk, Elastic, etc.)
   - Push or pull? (Loki â†’ SIEM)
   - Real-time or batch? (batch = cheaper)

### âš ï¸ [TIMING] Waarom Nu Wel/Niet?

**Implementeer NU als:**
- Compliance requirements (DORA, GDPR)
- Security team vraagt audit trail
- Break-glass procedures nodig

**Wacht LATER als:**
- Geen compliance eis
- Basic K8s audit logs voldoen
- Geen security team

### ğŸ”— [LAYER 1 LINK]

**Bouwt op:**
- RBAC (Layer 1) â†’ Audit RBAC changes
- Loki (Layer 1) â†’ Centralized audit log storage
- Vault (Layer 1) â†’ Audit secret access

---

## Resultaat Layer 2: Maturity Assessment

### Na Layer 2 Analyse Kun Je Beantwoorden:

âœ… **Service Mesh**: Hebben we dit nodig? (> 5 services, security/observability)  
âœ… **Distributed Tracing**: Lost dit een daadwerkelijk probleem op? (debugging > 1h)  
âœ… **Chaos Engineering**: Testen we HA of claimen we het alleen?  
âœ… **Policy Enforcement**: Automated validation of manual review?  
âœ… **Cost Visibility**: Waar gaat ons geld naartoe?  
âœ… **Multi-Region**: Nu nodig of later?  
âœ… **Observability**: Wat is pager-worthy?  
âœ… **Auditing**: Compliance requirement of overkill?  

### Layer 2 â†’ Layer 3 (Toekomst)

**Layer 3 zou gaan over:**
- Zero trust networking (full mutual TLS enforcement)
- Active multi-region (Cilium Cluster Mesh actief)
- Advanced chaos (automated, continuous)
- SLO-based automation (error budget policies)
- Cost optimization automation (rightsizing)
- Security automation (auto-remediation)

**Maar dat is alleen relevant als Layer 2 capabilities lopen en je **daadwerkelijk** complexity nodig hebt.**

---

## Conclusie: Complexity als Bewuste Keuze

Layer 2 is niet "de volgende stap na Layer 1".  
Layer 2 is "**welke extra capabilities zijn de complexity waard?**"

### Beslisregels:

1. **Start simpel**: Layer 1 first, Layer 2 alleen als trigger duidelijk is
2. **EÃ©n tegelijk**: Niet alle Layer 2 capabilities tegelijk (team overload!)
3. **Measure impact**: Elke capability moet meetbaar probleem oplossen
4. **Exit strategy**: Kunnen we terug als het niet werkt?

### Voor de Webshop Case:

**Waarschijnlijk WEL:**
- Distributed tracing (> 5 services, debugging issues)
- Cost visibility (budget concerns, multi-tenant)
- Policy enforcement (compliance, groeiend team)

**Waarschijnlijk NIET (nu):**
- Service mesh (< 10 services, network policies voldoen)
- Multi-region (single region voldoet, geen DR eis)
- Chaos engineering (eerst HA setup stabiliseren)

**Dit is de kracht van Layer 2: bewuste, onderbouwde keuzes in plaats van "we doen alles maar".**

---

**Auteur**: [@vanhoutenbos](https://github.com/vanhoutenbos)  
**Versie**: 2.0 (Decision Framework)  
**Datum**: December 2024  
**Licentie**: MIT
